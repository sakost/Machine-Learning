{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка и изучение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем библиотеки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv , DataFrame \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score , recall_score , f1_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from math import pi,exp\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.base import BaseEstimator,ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,num_iter = 100000):\n",
    "        self.num_iter=num_iter\n",
    "        self.beta=1\n",
    "        \n",
    "    def fit(self,x,y):\n",
    "        # x = x.toarray()\n",
    "        x = x.copy()\n",
    "        self.beta = np.ones(x.shape[1])\n",
    "        for i in range(self.num_iter):\n",
    "            h = self._sigmoid(x, self.beta)\n",
    "            gradient = self._gradient_descent(x, h, y)\n",
    "            self.beta =self._weight_update(self.beta, 0.1, gradient)\n",
    "    \n",
    "    def _sigmoid(self,X, weight):\n",
    "        z = np.dot(X, weight)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def _gradient_descent(self,X, H, Y):\n",
    "        return np.dot(X.T, (H - Y)) / Y.shape[0]\n",
    "    \n",
    "    def _weight_update(self,weight, learning_rate, gradient):\n",
    "        return weight - learning_rate * gradient\n",
    "    \n",
    "    \n",
    "    def predict(self,test):\n",
    "        # test = test.toarray()\n",
    "        final_result=[]\n",
    "        \n",
    "        result = self._sigmoid(test, self.beta)\n",
    "        \n",
    "        for i in result:\n",
    "            final_result.append(self._onepred(i))\n",
    "        \n",
    "        \n",
    "        return final_result\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _onepred(self,x):\n",
    "        if x < 0.5:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYSVM(BaseEstimator, ClassifierMixin):\n",
    "   \n",
    "    def __init__(self, etha=0.1, alpha=0.2, epochs=990):\n",
    "        self.epochs = epochs\n",
    "        self.etha = etha\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X_train, Y_train):\n",
    "        # X_train = X_train.toarray()\n",
    "        X_test = X_test.copy()\n",
    "        \n",
    "        for i in range(len(Y_train)):\n",
    "            if Y_train.iloc[i] == 0:\n",
    "                Y_train.iloc[i] = -1\n",
    "        \n",
    "        X_train = self._add_bias_feature(X_train)\n",
    "        self.w = np.random.normal(loc=0, scale=0.05, size=X_train.shape[1])#задаем первые веса\n",
    "        \n",
    "        \n",
    "        \n",
    "        for epoch in range(self.epochs): \n",
    "            \n",
    "            for i,x in enumerate(X_train):\n",
    "                margin = Y_train.iloc[i]*np.dot(self.w,X_train[i])\n",
    "                if margin >= 1: \n",
    "                    self.w = self.w - self.etha*self.alpha*self.w/self.epochs\n",
    "                    \n",
    "                else: \n",
    "                    self.w = self.w +\\\n",
    "                    self.etha*(Y_train.iloc[i]*X_train[i] - self.alpha*self.w/self.epochs)\n",
    "                    \n",
    "        Y_train[Y_train == -1] = 0\n",
    "     \n",
    "    \n",
    "    def _add_bias_feature(self,a):\n",
    "        \n",
    "        a_extended = np.zeros((a.shape[0],a.shape[1]+1))\n",
    "        a_extended[:,:-1] = a\n",
    "        a_extended[:,-1] = int(1)  \n",
    "        return a_extended\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        # X = X.toarray()\n",
    "        y_pred = []\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            y_pred.append(np.sign(1+np.dot(self.w[1:],X[i])))\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i]==-1:\n",
    "                y_pred[i]=0\n",
    "\n",
    "        return y_pred         \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм k ближайших соседей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, k=3,h=1):\n",
    "        self.h=h\n",
    "        self.k = k\n",
    "    \n",
    "      \n",
    "    def fit(self, X, y):\n",
    "        # X = X.toarray()\n",
    "        X = pd.DataFrame(X)\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "   \n",
    "    def _jadro_K(self,z):    \n",
    "        return ((2*pi)**(-0.5))*exp(-0.5*z**(2))\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # X_test = X_test.toarray()\n",
    "        X_test = X_test.copy()\n",
    "        X_test = pd.DataFrame(X)\n",
    "        output = []#\n",
    "        for i in range(len(X_test)):\n",
    "            d = []\n",
    "            votes = []\n",
    "            for j in range(len(X_train)):\n",
    "                \n",
    "                dist = scipy.spatial.distance.euclidean(self.X_train.iloc[j] , X_test.iloc[i])\n",
    "                 \n",
    "                weight=self._jadro_K(scipy.spatial.distance.euclidean(self.X_train.iloc[j] , X_test.iloc[i])/self.h)\n",
    "                d.append([dist, j,weight])\n",
    "            \n",
    "            d.sort()\n",
    "            d = d[0:self.k]\n",
    "            zero_score=0\n",
    "            one_score=0\n",
    "            for a, j, k in d:\n",
    "                votes.append(y_train.iloc[j])\n",
    "            for j in range(len(votes)):\n",
    "                if votes[j]==0:\n",
    "                    zero_score=zero_score+1*d[j][2]\n",
    "                if votes[j]==1:\n",
    "                    one_score=one_score+1*d[j][2]\n",
    "            if zero_score>one_score:\n",
    "                ans=0\n",
    "            if  one_score>zero_score:\n",
    "                ans=1\n",
    "            output.append(ans)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наивный байесовский классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaivBaisClassificator(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "   \n",
    "    def __init__(self):\n",
    "        self.out={}\n",
    "    \n",
    "    def _make_likelihood_Table(self,labels_and_serie):\n",
    "        a=labels_and_serie[labels_and_serie['churn']==1][labels_and_serie.keys()[1]].value_counts()/len(labels_and_serie[labels_and_serie['churn']==1][labels_and_serie.keys()[1]])\n",
    "        b=labels_and_serie[labels_and_serie['churn']==0][labels_and_serie.keys()[1]].value_counts()/len(labels_and_serie[labels_and_serie['churn']==0][labels_and_serie.keys()[1]])\n",
    "        out_dataframe=DataFrame()\n",
    "        if set(a.keys())==set(b.keys()):\n",
    "        \n",
    "            out_dataframe[str(a.name)+'_1']=a\n",
    "            out_dataframe[str(b.name)+'_0']=b\n",
    "            return out_dataframe\n",
    "        if len(set(a.keys())-set(b.keys()))!=0:\n",
    "            for m in list(set(a.keys())-set(b.keys())):\n",
    "                b[m]=1/len(labels_and_serie[labels_and_serie['churn']==0][labels_and_serie.keys()[1]])\n",
    "        if len(set(b.keys())-set(a.keys()))!=0:\n",
    "            for m in list(set(b.keys())-set(a.keys())):\n",
    "                a[m]=1/len(labels_and_serie[labels_and_serie['churn']==1][labels_and_serie.keys()[1]])\n",
    "        out_dataframe[str(a.name)+'_1']=a\n",
    "        out_dataframe[str(b.name)+'_0']=b\n",
    "        return out_dataframe\n",
    "    \n",
    "    \n",
    "    def fit(self,train,test):\n",
    "        # train = train.toarray()\n",
    "        train = pd.DataFrame(train.copy())\n",
    "        data=DataFrame()\n",
    "        data=train.copy()\n",
    "        data['Survived']=test.values\n",
    "        dict_of_df={}\n",
    "        for i in data.columns[0:-1]:\n",
    "            dict_of_df[i]=self._make_likelihood_Table(data[['Survived',i]])\n",
    "        self.out=dict_of_df\n",
    "    \n",
    "    \n",
    "    def _onepredict(self,test):\n",
    "        zero=1\n",
    "        one=1\n",
    "        for i in test.keys():\n",
    "            \n",
    "            try:\n",
    "                one=one*float(self.out[i][i+'_1'][test[i]])\n",
    "                zero=zero*float(self.out[i][i+'_0'][test[i]])\n",
    "            except:\n",
    "                one=one*1\n",
    "                zero=zero*1\n",
    "        if zero>one:\n",
    "        \n",
    "            return 0\n",
    "        else:\n",
    "        \n",
    "            return 1\n",
    "        \n",
    "\n",
    "    def predict(self,test_dataset):\n",
    "        # test_dataset = test_dataset.toarray()\n",
    "        test_dataset = pd.DataFrame(test_dataset.copy())\n",
    "        final_predict=[]\n",
    "        for k in range(test_dataset.shape[0]):\n",
    "            final_predict.append(self._onepredict(test_dataset.iloc[k]))\n",
    "        return final_predict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "trans_pipeline = ColumnTransformer([\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_csv('data/transformed_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred,true,name):\n",
    "    print(f'metrics for {name}\\n\\n\\n')\n",
    "    print('confusion_matrix = \\n',confusion_matrix(pred,true),'\\n\\n\\n')\n",
    "    print('accuracy_score = ',accuracy_score(pred,true))\n",
    "    print('recall_score = ',recall_score(pred,true))\n",
    "    \n",
    "    try:\n",
    "        print('precision_score=', precision_score(pred,true))\n",
    "    except ValueError:\n",
    "        pass\n",
    "        print('precision_score=', precision_score(pred,true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "def work_with_model(model,params,name):\n",
    "    model = model()\n",
    "    model = Pipeline([('transformer',trans_pipeline),('clf',model)])\n",
    "    grid = GridSearchCV(estimator=model,param_grid =params,cv=5 )  \n",
    "    grid.fit(dataset.drop(['churn'],axis=1),dataset['churn'])\n",
    "    with open(os.path.join(\"params\", name+'_best_params.txt'), 'a') as f:\n",
    "        f.write(str(grid.best_estimator_))\n",
    "    \n",
    "    pkl_filename = name+'_best_model.pkl'\n",
    "    \n",
    "    with open(os.path.join(\"params\", pkl_filename), 'wb') as file: \n",
    "        pickle.dump(grid.best_estimator_, file)\n",
    "        \n",
    "    metrics(grid.predict(dataset.drop(['churn'],axis=1)),dataset['churn'],name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters  = {'clf__num_iter':[100,500,1000,2000,3000,5000,10000]}\n",
    "\n",
    "work_with_model(LogReg,parameters,'custom_logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters  = {'clf__max_iter':[100,500,1000,2000,3000,5000,10000]}\n",
    "\n",
    "work_with_model(LogisticRegression,parameters,'sklearn_logreg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters  = {'clf__etha':[0.1,0.2,0.3],\n",
    "               'clf__alpha':[0.1,0.2,0.3], \n",
    "               'clf__epochs':[100,500,1000]}\n",
    "\n",
    "work_with_model(MYSVM,parameters,'custom_svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters  = {'clf__C':[0.1,0.2,0.3],\n",
    "               'clf__gamma':[0.1,0.2,0.3], \n",
    "               'clf__max_iter':[100,500,1000]}\n",
    "\n",
    "work_with_model(svm.SVC,parameters,'sklearn_svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритм k ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters  = {'clf__k':[2,3,4],\n",
    "               'clf__h':[1,0.1,0.01], \n",
    "               }\n",
    "\n",
    "work_with_model(KNN,parameters,'custom_KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters  = {'clf__n_neighbors':[2,3,4],\n",
    "               'clf__weights':['uniform', 'distance']\n",
    "               }\n",
    "\n",
    "work_with_model(KNeighborsClassifier,parameters,'sklearn_KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный байесовский классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters  = {}\n",
    "\n",
    "work_with_model(NaivBaisClassificator,parameters,'custom_NaivBaisClassificator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters  = {}\n",
    "\n",
    "work_with_model(BernoulliNB,parameters,'sklearn_NaivBaisClassificator')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
